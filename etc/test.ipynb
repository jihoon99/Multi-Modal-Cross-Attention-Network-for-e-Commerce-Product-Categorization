{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_fn': './data/train_df_negOne', 'pretrained_model_name': 'kykim/bert-kor-base', 'use_albert': False, 'gpu_id': 0, 'verbose': 2, 'batch_size': 128, 'warmup_ratio': 0.2, 'adam_epsilon': 1e-08, 'use_radam': True, 'valid_ratio': 0.2, 'max_length': 30, 'num_b': 57, 'num_m': 552, 'num_s': 3190, 'num_d': 404, 'scheduler': True, 'n_epochs': 1, 'load_model_path_text': './saved/text/text.06.-0.93-0.88-.0.68-0.09-.pth', 'load_model_path_img': './saved/img/img_ffn.09.-0.77-0.68-.0.66-0.88-.pth', 'test_fn': './data/test_df', 'test_img_path': './data/test_img_feat.h5', 'img_path': './data/train_img_feat.h5', 'validation_mode': True, 'modality': 'both', 'predict_fn': './predict/valid/multi/multi_simple_6th_predict.csv', 'logging_fn': './predict/valid/multi/multi_simple_6th_predict.log', 'load_model_path_both': './saved/multi/multi_simple_concat.06.-0.93-0.89-.0.90-0.97-.pth', 'n_block': 6, 'multiModal_type': 'simple', 'num_head': 6, 'config_fn': './predict/valid/multi/multi_simple_config'}\n",
      "modality :  both\n",
      "kykim/bert-kor-base\n"
     ]
    }
   ],
   "source": [
    "from logging import raiseExceptions\n",
    "from multiprocessing.sharedctypes import Value\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "'''\n",
    "adam_epsilon=1e-08, \n",
    "batch_size=128, \n",
    "gpu_id=0, \n",
    "lr=5e-05, \n",
    "max_length=30, \n",
    "modality='text', \n",
    "model_fn='./saved/text/text.pth', \n",
    "n_epochs=6, \n",
    "num_b=57, num_d=404, num_m=552, num_s=3190, pretrained_model_name='kykim/bert-kor-base', train_fn='./data/train_df_negOne', use_albert=False, use_radam=True, valid_ratio=0.2, verbose=2, warmup_ratio=0.2)\n",
    "'''\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "from transformers import BertForSequenceClassification, AlbertForSequenceClassification\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "import torch_optimizer as custom_optim\n",
    "\n",
    "# from process.bert_trainer import BertTrainer as Trainer\n",
    "from process.bert_dataset1 import ClassificationDataset, ClassificationCollator\n",
    "from process.utils import read_text\n",
    "\n",
    "from model.multimodel import MultiModalClassifier, BertClassifier\n",
    "from trainer_valid import ValidationForBert\n",
    "\n",
    "\n",
    "def define_argparser():\n",
    "    p = argparse.ArgumentParser()\n",
    "\n",
    "    p.add_argument('--train_fn', default='./data/train_df_negOne')    # 학습에 사용될 파일이름. // train_df1은 label 1씩 뺀것.\n",
    "    # Recommended model list:\n",
    "    # - kykim/bert-kor-base         # bs : 80\n",
    "    # - kykim/albert-kor-base       # bs : 80\n",
    "    # - beomi/kcbert-base           # bs : 80\n",
    "    # - beomi/kcbert-large          # bs : 30\n",
    "    p.add_argument('--pretrained_model_name', type=str, default='kykim/bert-kor-base')  # 다운받을 모델명(인터넷기준) # kykim/albert-kor-base\n",
    "    p.add_argument('--use_albert', action='store_true', default=False)\n",
    "    \n",
    "    p.add_argument('--gpu_id', type=int, default=0)\n",
    "    p.add_argument('--verbose', type=int, default=2)\n",
    "\n",
    "    p.add_argument('--batch_size', type=int, default=128)\n",
    "\n",
    "    p.add_argument('--warmup_ratio', type=float, default=.2)         # transformer가 학습이 까다로워.. 웜업함. // 위에 두줄은 안건들여도됨.\n",
    "    p.add_argument('--adam_epsilon', type=float, default=1e-8)\n",
    "    # If you want to use RAdam, I recommend to use LR=1e-4.\n",
    "    # Also, you can set warmup_ratio=0.\n",
    "    p.add_argument('--use_radam', default = True)                   # radam을 쓸때는 warup_ratio를 0으로 해야함. 그리고 추천한 lr = 1e-4이다.\n",
    "    p.add_argument('--valid_ratio', type=float, default=.2)\n",
    "\n",
    "    p.add_argument('--max_length', type=int, default=30)\n",
    "    p.add_argument(\"--num_b\", type=int, default=57)\n",
    "    p.add_argument(\"--num_m\", type=int, default=552)\n",
    "    p.add_argument(\"--num_s\", type=int, default=3190)\n",
    "    p.add_argument(\"--num_d\", type=int, default=404)\n",
    "    p.add_argument(\"--scheduler\", default=True)\n",
    "    p.add_argument('--n_epochs', type=int, default=1)    ## text제외 10이었음.            # base기준 2번만 돌려도 괜춘한 성능을 보임.\n",
    "    p.add_argument(\"--load_model_path_text\", default='./saved/text/text.06.-0.93-0.88-.0.68-0.09-.pth')                                 ##############################   pre-trained model사용하려면 모델 불러워야함.\n",
    "    p.add_argument(\"--load_model_path_img\", default = './saved/img/img_ffn.09.-0.77-0.68-.0.66-0.88-.pth')\n",
    "\n",
    "    ########     validating       ############\n",
    "    p.add_argument(\"--test_fn\", default='./data/test_df')                              ## test_df, dev_df\n",
    "    p.add_argument(\"--dev_fn\", default='./data/dev_df')                              ## test_df, dev_df\n",
    "    p.add_argument(\"--test_img_path\", type=str, default='./data/test_img_feat.h5')\n",
    "\n",
    "    p.add_argument(\"--img_path\", type=str, default='./data/train_img_feat.h5')         ##############################   이것도 바껴야함.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #########################################################    변경할 것들    #####################################################\n",
    "    p.add_argument('--validation_mode', type=bool, default=True)                       ## True : train-valid중 valid를... False: test\n",
    "    p.add_argument('--dev_mode', type=bool, default=True)                       ## True : train-valid중 valid를... False: test\n",
    "\n",
    "    # dev가 true이면    dev_df임.\n",
    "\n",
    "    #########    저장할 모델의 위치    ##############\n",
    "    p.add_argument(\"--modality\", type=str, default='both')                             ##############################   modality : text, img, both\n",
    "    p.add_argument(\"--predict_fn\", default = './predict/dev/multi/multi_simple_6th_predict.csv')\n",
    "    p.add_argument(\"--logging_fn\", default = './predict/dev/multi/multi_simple_6th_predict.log')\n",
    "\n",
    "    p.add_argument(\"--load_model_path_both\", default = './saved/multi/multi_simple_concat.06.-0.93-0.89-.0.90-0.97-.pth')\n",
    "\n",
    "    p.add_argument(\"--n_block\", default = 1, type=int)\n",
    "    p.add_argument(\"--multiModal_type\", default = 'cross')\n",
    "    p.add_argument(\"--num_head\", default = 1, type=int)\n",
    "    p.add_argument(\"--config_fn\", type=str, default='./predict/dev/multi/multi_simple_config')\n",
    "    # p.add_argument(\"--scheduler\", default=True)\n",
    "    # p.add_argument(\"--load_model_path\", default='./saved/text/text.06.-0.93-0.88-.0.68-0.09-.pth')                                 ##############################   pre-trained model사용하려면 모델 불러워야함.\n",
    "    # p.add_argument('--lr', type=float, default=5e-5) # 5e-5  / 0.001\n",
    "\n",
    "\n",
    "# python inference.py --predict_fn ./predict/test/multi/test_multi_simple_6th_predict --logging_fn ./predict/test/multi/test_multi_simple_6th_predict.log --n_block 2 --multiModal_type simple --config_fn ./predict/test/multi/test_multi_simple_config --load_model_path_both ./saved/multi/multi_simple_concat.06.-0.93-0.89-.0.90-0.97-.pth && python inference.py --predict_fn ./predict/test/multi/test_multi_cross_2block_6th_predict --logging_fn ./predict/test/multi/test_multi_cross_2block_6th_predict.log --n_block 2 --multiModal_type cross --config_fn ./predict/test/multi/test_multi_cross_2block_config --load_model_path_both ./saved/multi/multi_cross.06.-0.94-0.90-.0.90-0.98-.pth && python inference.py --predict_fn ./predict/test/multi/test_multi_cross_2block_6th_predict.csv --logging_fn ./predict/test/multi/test_multi_cross_2block_6th_predict.log --n_block 2 --multiModal_type cross --config_fn ./predict/test/multi/test_multi_cross_2block_config --load_model_path_both ./saved/multi/multi_cross.06.-0.94-0.90-.0.90-0.98-.pth && python inference.py --predict_fn ./predict/test/multi/test_multi_cross_6block_6th_predict.csv --logging_fn ./predict/test/multi/test_multi_cross_6block_6th_predict.log --n_block 6 --multiModal_type cross --config_fn ./predict/test/multi/test_multi_cross_6block_config --load_model_path_both ./saved/multi/multi_cross_6block.06.-0.94-0.90-.0.90-0.98-.pth && python inference.py --predict_fn ./predict/test/multi/test_multi_cross_12block_6th_predict.csv --logging_fn ./predict/test/multi/test_multi_cross_12block_6th_predict.log --n_block 12 --multiModal_type cross --config_fn ./predict/test/multi/test_multi_cross_12block_config --load_model_path_both ./saved/multi/multi_cross_12block.06.-0.94-0.90-.0.91-0.98-.pth && python inference.py --predict_fn ./predict/test/multi/test_multi_cross_6block_2head_6th_predict.csv --logging_fn ./predict/test/multi/test_multi_cross_6block_2head_6th_predict.log --n_block 6 --num_head 2 --multiModal_type cross --config_fn ./predict/test/multi/test_multi_cross_6block_2head_config --load_model_path_both ./saved/multi/multi_cross_6block_2head.06.-0.94-0.90-.0.91-0.98-.pth && python inference.py --predict_fn ./predict/test/multi/test_multi_cross_6block_4head_6th_predict.csv --logging_fn ./predict/test/multi/test_multi_cross_6block_4head_6th_predict.log --n_block 6 --num_head 4 --multiModal_type cross --config_fn ./predict/test/multi/test_multi_cross_6block_4head_config --load_model_path_both ./saved/multi/multi_cross_6block_4head.06.-0.94-0.90-.0.90-0.98-.pth && python inference.py --predict_fn ./predict/test/multi/test_multi_cross_6block_6head_6th_predict.csv --logging_fn ./predict/test/multi/test_multi_cross_6block_6head_6th_predict.log --n_block 6 --num_head 6 --multiModal_type cross --config_fn ./predict/test/multi/test_multi_cross_6block_6head_config --load_model_path_both ./saved/multi/multi_cross_6block_6head.06.-0.94-0.90-.0.91-0.97-.pth\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ##################\n",
    "    ##################\n",
    "    #################\n",
    "    #   trainer의 0이상을 -1 이상으로 확인하기\n",
    "    ################\n",
    "    #################\n",
    "    ################\n",
    "\n",
    "    config = p.parse_args()\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_loaders(fn, tokenizer, config, valid_ratio=.2 ):\n",
    "    '''\n",
    "        fn : train_df path\n",
    "        tokenizer : bertTokenizer\n",
    "        img : img path\n",
    "        \n",
    "    '''\n",
    "    # Get list of labels and list of texts.\n",
    "    train_df=pd.read_csv(fn)\n",
    "    train_df['img_idx'] = train_df.index\n",
    "\n",
    "    texts=train_df['product']\n",
    "    bcateid = train_df['bcateid']\n",
    "    mcateid = train_df['mcateid']\n",
    "    scateid = train_df['scateid']\n",
    "    dcateid = train_df['dcateid']\n",
    "    labels = list(zip(bcateid, mcateid, scateid, dcateid))\n",
    "    imgs = train_df['img_idx']\n",
    "    pids = train_df['pid']\n",
    "\n",
    "    shuffled = list(zip(texts, labels, imgs, pids))  # 묶은다음 셔플링.\n",
    "    random.shuffle(shuffled)\n",
    "    texts = [e[0] for e in shuffled]\n",
    "    labels = [e[1] for e in shuffled]\n",
    "    imgs = [e[2] for e in shuffled]\n",
    "    pids = [e[3] for e in shuffled]\n",
    "\n",
    "    idx = int(len(texts) * (1 - valid_ratio))\n",
    "\n",
    "    # Get dataloaders using given tokenizer as collate_fn.\n",
    "    train_loader = DataLoader(\n",
    "        ClassificationDataset(texts[:idx], labels[:idx], imgs[:idx], config.img_path, pids[:idx]),\n",
    "        batch_size= config.batch_size,      ########################################\n",
    "        shuffle=True,\n",
    "        collate_fn=ClassificationCollator(tokenizer, config.max_length), ########################\n",
    "    )\n",
    "\n",
    "\n",
    "    # train_df.iloc[idx:].to_csv(\"validation.csv\", index=False)\n",
    "    valid_loader = DataLoader(\n",
    "        ClassificationDataset(texts[idx:], labels[idx:], imgs[idx:], config.img_path, pids[idx:]),\n",
    "        batch_size=config.batch_size,       ##########################################\n",
    "        collate_fn=ClassificationCollator(tokenizer, config.max_length), #######################\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def get_loaders_test(fn, tokenizer, config):\n",
    "    '''\n",
    "        fn : train_df path\n",
    "        tokenizer : bertTokenizer\n",
    "        img : img path\n",
    "        \n",
    "    '''\n",
    "    # Get list of labels and list of texts.\n",
    "    train_df=pd.read_csv(fn)\n",
    "    print(train_df.head())\n",
    "    train_df['img_idx'] = train_df.index\n",
    "\n",
    "    texts=train_df['product']\n",
    "    bcateid = train_df['bcateid']\n",
    "    mcateid = train_df['mcateid']\n",
    "    scateid = train_df['scateid']\n",
    "    dcateid = train_df['dcateid']\n",
    "    labels = list(zip(bcateid, mcateid, scateid, dcateid))\n",
    "    imgs = train_df['img_idx']\n",
    "\n",
    "    # Get dataloaders using given tokenizer as collate_fn.\n",
    "    train_loader = DataLoader(\n",
    "        ClassificationDataset(texts, labels, imgs, config.img_path),\n",
    "        batch_size= config.batch_size,      ########################################\n",
    "        collate_fn=ClassificationCollator(tokenizer, config.max_length), ########################\n",
    "    )\n",
    "\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_optimizer(model, config):\n",
    "    if config.use_radam:\n",
    "        optimizer = custom_optim.RAdam(model.parameters(), lr=config.lr)\n",
    "    else:\n",
    "        # Prepare optimizer and schedule (linear warmup and decay)\n",
    "        no_decay = ['bias', 'LayerNorm.weight']    # 애들은 no decay한데.\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.01\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        optimizer = optim.AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=config.lr,\n",
    "            eps=config.adam_epsilon\n",
    "        )\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "config = torch.load(\"./predict/valid/multi/multi_simple_config\")\n",
    "config = vars(config['config'])\n",
    "config = edict(config)\n",
    "print(config)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('modality : ', config.modality)\n",
    "print(config.pretrained_model_name)\n",
    "# Get pretrained tokenizer.\n",
    "tokenizer = BertTokenizerFast.from_pretrained(config.pretrained_model_name)    # 적당히 전처리 된 text를 넣으면됨.\n",
    "# Get dataloaders using tokenizer from untokenized corpus.\n",
    "\n",
    "if config.validation_mode:\n",
    "    _, valid_loader = get_loaders(\n",
    "        config.train_fn,\n",
    "        tokenizer,\n",
    "        valid_ratio=config.valid_ratio,\n",
    "        config = config\n",
    "    )\n",
    "    mini = next(iter(valid_loader))\n",
    "\n",
    "else:\n",
    "    test_fn = config.dev_fn if config.dev_mode else config.test_fn\n",
    "\n",
    "    valid_loader = get_loaders_test(\n",
    "        test_fn,\n",
    "        tokenizer,\n",
    "        config=config\n",
    "    )\n",
    "    mini = next(iter(valid_loader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>product</th>\n",
       "      <th>bcateid</th>\n",
       "      <th>mcateid</th>\n",
       "      <th>scateid</th>\n",
       "      <th>dcateid</th>\n",
       "      <th>img_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430046</th>\n",
       "      <td>P2412454373</td>\n",
       "      <td>Volkswagen  폭스바겐 VW1419V-SVBK 본사정품 여성용</td>\n",
       "      <td>19</td>\n",
       "      <td>131</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>6937900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pid                                 product  ...  dcateid  img_idx\n",
       "430046  P2412454373  Volkswagen  폭스바겐 VW1419V-SVBK 본사정품 여성용  ...       -2  6937900\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = pd.read_csv(\"validation.csv\")\n",
    "aaa[aaa.pid=='P2412454373']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Q4564270519',\n",
       " 'P2412454373',\n",
       " 'X3283266744',\n",
       " 'G4186461142',\n",
       " 'V1262201399',\n",
       " 'P4539388728',\n",
       " 'N3746304406',\n",
       " 'J3957102515',\n",
       " 'Q3766398650',\n",
       " 'K4154460947',\n",
       " 'M2989848478',\n",
       " 'H4681234207',\n",
       " 'H4687095127',\n",
       " 'Y4404398396',\n",
       " 'W4249018378',\n",
       " 'X4619873316',\n",
       " 'N2482738071',\n",
       " 'I4730373980',\n",
       " 'R3752461526',\n",
       " 'H4718653737',\n",
       " 'T4252545707',\n",
       " 'R2644558638',\n",
       " 'L4315594982',\n",
       " 'V2473580237',\n",
       " 'P657149189',\n",
       " 'T4042032222',\n",
       " 'K3897213687',\n",
       " 'W911937221',\n",
       " 'F4532260967',\n",
       " 'R3067581534',\n",
       " 'N3315095863',\n",
       " 'J4628193831',\n",
       " 'J3782856182',\n",
       " 'L4397981454',\n",
       " 'U4602724536',\n",
       " 'W3089018568',\n",
       " 'O3922406370',\n",
       " 'N2447670376',\n",
       " 'V3416325644',\n",
       " 'V3914769804',\n",
       " 'J3727715433',\n",
       " 'G4472201065',\n",
       " 'L4283912820',\n",
       " 'H3818151326',\n",
       " 'K2644276145',\n",
       " 'Y3762875550',\n",
       " 'M3136315592',\n",
       " 'H2942240660',\n",
       " 'O3943822845',\n",
       " 'P2940342524',\n",
       " 'Q4667491460',\n",
       " 'O3124112715',\n",
       " 'T3005228340',\n",
       " 'P3664407638',\n",
       " 'J3564674393',\n",
       " 'N3380241599',\n",
       " 'G4731198379',\n",
       " 'W4527296474',\n",
       " 'M3877683604',\n",
       " 'U4546833879',\n",
       " 'U4391192401',\n",
       " 'M3429278469',\n",
       " 'S3880280751',\n",
       " 'V4639391805',\n",
       " 'W4639947421',\n",
       " 'W3034627622',\n",
       " 'P4435213692',\n",
       " 'R4669386211',\n",
       " 'Q4301755120',\n",
       " 'N4758869882',\n",
       " 'Z1937619483',\n",
       " 'Z2980790852',\n",
       " 'S4268228795',\n",
       " 'G1636163159',\n",
       " 'Z4548953582',\n",
       " 'R4156310232',\n",
       " 'H4326156943',\n",
       " 'Q4339935211',\n",
       " 'K3338192017',\n",
       " 'R4285927995',\n",
       " 'L4430122196',\n",
       " 'V4188201174',\n",
       " 'V2351407908',\n",
       " 'G2695284581',\n",
       " 'I1212424712',\n",
       " 'R4660670842',\n",
       " 'H3144998751',\n",
       " 'Q4704603003',\n",
       " 'N1947597824',\n",
       " 'T3762870111',\n",
       " 'O4508096204',\n",
       " 'L4536559870',\n",
       " 'S4362244597',\n",
       " 'U4652423909',\n",
       " 'O4479857831',\n",
       " 'L4465738122',\n",
       " 'T4434827210',\n",
       " 'J3794266005',\n",
       " 'Q3872773993',\n",
       " 'V4536796685',\n",
       " 'Z4549008927',\n",
       " 'Y2655426362',\n",
       " 'L4081793135',\n",
       " 'G4081035284',\n",
       " 'G4593474419',\n",
       " 'L3998717068',\n",
       " 'V4327117794',\n",
       " 'K2901352756',\n",
       " 'L4405005710',\n",
       " 'V3903435605',\n",
       " 'J3724398375',\n",
       " 'P3642519421',\n",
       " 'P4576284920',\n",
       " 'Y3071131078',\n",
       " 'R4719574600',\n",
       " 'G4052331822',\n",
       " 'W3911266731',\n",
       " 'Q3646176237',\n",
       " 'O3709706380',\n",
       " 'Q3479763042',\n",
       " 'U4252227882',\n",
       " 'P4486126399',\n",
       " 'X3040577894',\n",
       " 'S4536996721',\n",
       " 'N4724021467',\n",
       " 'X4343597759',\n",
       " 'Z2450101002',\n",
       " 'V4642015286']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini['pid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  23,  205,  323,   -2],\n",
       "        [  19,  131,   -2,   -2],\n",
       "        [  10,  222,   -2,   -2],\n",
       "        [  16,  278,  719,   -2],\n",
       "        [  31,  207,  327,   29],\n",
       "        [  10,  219,  826,   -2],\n",
       "        [  22,  410,   -2,   -2],\n",
       "        [   5,    5,   32,   18],\n",
       "        [  43,  136,  935,   -2],\n",
       "        [   5,    5,    6,   13],\n",
       "        [  10,  222,  902,   -2],\n",
       "        [  39,  234,  574,   -2],\n",
       "        [  15,  221,  792,   -2],\n",
       "        [  39,  182,   -2,   -2],\n",
       "        [  40,  127,  607,   -2],\n",
       "        [  12,   11,  212,   -2],\n",
       "        [  42,  108,  657,   -2],\n",
       "        [   9,    8, 2427,   -2],\n",
       "        [  33,  331,  836,   -2],\n",
       "        [  40,  127, 1322,   -2],\n",
       "        [   2,    2,   37,    9],\n",
       "        [  27,  106,  250,   -2],\n",
       "        [   6,    6,    9,   -2],\n",
       "        [   8,    6,  171,   -2],\n",
       "        [  14,  396, 1528,   -2],\n",
       "        [  15,   37,  504,   -2],\n",
       "        [  10,  222,   -2,   -2],\n",
       "        [  17,   20,  400,   -2],\n",
       "        [   6,  375,  837,   -2],\n",
       "        [  22,  270,  496,   -2],\n",
       "        [  43,  136,   -2,   -2],\n",
       "        [  42,  400, 1242,   -2],\n",
       "        [   6,   87,  158,   -2],\n",
       "        [   6,   42,   99,   -2],\n",
       "        [  21,  241,  411,   -2],\n",
       "        [   2,    2,  374,   -2],\n",
       "        [   7,  179, 1619,   -2],\n",
       "        [  10,  222,   -2,   -2],\n",
       "        [  10,  219,  826,   -2],\n",
       "        [  16,  139,  204,   -2],\n",
       "        [  12,   11,  251,   -2],\n",
       "        [  12,   11,   13,   -2],\n",
       "        [   8,    6,  492,   -2],\n",
       "        [  52,  463, 2070,   -2],\n",
       "        [  39,   99,  950,   -2],\n",
       "        [  21,   25, 1778,   -2],\n",
       "        [  18,  107, 2035,   -2],\n",
       "        [  10,   14,  341,   -2],\n",
       "        [  36,  166,  483,   -2],\n",
       "        [  13,   16,  103,   11],\n",
       "        [   1,  198,   -2,   -2],\n",
       "        [   2,    2,   37,   -2],\n",
       "        [  15,  217,  873,   -2],\n",
       "        [  43,  436,   -2,   -2],\n",
       "        [  39,  124, 1693,   -2],\n",
       "        [  34,  385, 2266,   -2],\n",
       "        [  49,  255, 1207,   -2],\n",
       "        [  38,  209,  329,   -2],\n",
       "        [  10,  180,  281,   -2],\n",
       "        [  15,  221, 1156,   -2],\n",
       "        [  34,  385,   -2,   -2],\n",
       "        [   2,    2,  374,   -2],\n",
       "        [   5,   13,   15,   -2],\n",
       "        [  36,  158,  402,   -2],\n",
       "        [  21,   26,  121,   -2],\n",
       "        [  27,   93,  134,   -2],\n",
       "        [   8,   66,   86,   -2],\n",
       "        [  23,   30,   33,   -2],\n",
       "        [  33,   61,  115,   -2],\n",
       "        [   8,   50,  545,   -2],\n",
       "        [  35,  134,  844,   -2],\n",
       "        [  50,  239,  604,  304],\n",
       "        [  12,  337, 2525,   -2],\n",
       "        [  52,  463, 2097,  190],\n",
       "        [  20,   34,   38,   -2],\n",
       "        [   5,    5,   32,   18],\n",
       "        [  10,  416,   -2,   -2],\n",
       "        [  19,  347, 1278,   -2],\n",
       "        [   1,   43,  261,   -2],\n",
       "        [  48,  300,  617,   -2],\n",
       "        [  34,  385, 1177,   -2],\n",
       "        [  16,  178,  751,   -2],\n",
       "        [  13,   73,  132,   -2],\n",
       "        [  33,  261,  766,   -2],\n",
       "        [  39,  234,   -2,   -2],\n",
       "        [  42,  214, 1064,  136],\n",
       "        [   0,  115, 1556,   -2],\n",
       "        [   2,    2,   37,    9],\n",
       "        [  52,  463, 2070,  186],\n",
       "        [  21,   26,  121,   -2],\n",
       "        [   2,  163,  248,   -2],\n",
       "        [  33,  261, 1144,   -2],\n",
       "        [  24,   31,   42,   -2],\n",
       "        [   2,    2,   37,    7],\n",
       "        [  52,  463, 2070,   -2],\n",
       "        [  44,  181,   -2,   -2],\n",
       "        [  13,   48,   58,   -2],\n",
       "        [  14,  267,  484,   -2],\n",
       "        [  19,   23,  507,   -2],\n",
       "        [  16,  139,  204,   -2],\n",
       "        [  13,   12,   14,   -2],\n",
       "        [  19,   23,  353,   -2],\n",
       "        [  10,  215,  338,   -2],\n",
       "        [   5,   13,  148,   -2],\n",
       "        [  13,  140,  296,   -2],\n",
       "        [  34,  385, 1177,   -2],\n",
       "        [   2,    2,  374,   -2],\n",
       "        [  40,  127,   -2,   -2],\n",
       "        [   6,  202,   80,   -2],\n",
       "        [   8,   60,  230,   -2],\n",
       "        [  50,  216, 1533,   -2],\n",
       "        [  19,  131,   -2,   -2],\n",
       "        [  16,  139,  204,   -2],\n",
       "        [   7,  213,  781,   -2],\n",
       "        [  15,  217,   -2,   -2],\n",
       "        [  10,  222,  364,   -2],\n",
       "        [  19,   59,  112,   -2],\n",
       "        [  43,  116,   -2,   -2],\n",
       "        [  23,   30,   33,    4],\n",
       "        [   5,   13,  148,   -2],\n",
       "        [  10,  397, 1509,   -2],\n",
       "        [  39,  182, 1113,   -2],\n",
       "        [  15,  303, 1893,   -2],\n",
       "        [  13,   48,  774,   -2],\n",
       "        [  49,  200,  478,   -2],\n",
       "        [   6,   84,   86,   -2],\n",
       "        [  39,   99,  950,   -2],\n",
       "        [  33,  261,  745,   -2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30]) torch.Size([128, 30]) torch.Size([128, 4]) torch.Size([128, 2048])\n",
      "|valid| = 1627008\n",
      "#total_iters = 12711 #warmup_iters = 2542\n",
      "both\n",
      "model :  both\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(mini['input_ids'].shape, mini['attention_mask'].shape, mini['labels'].shape, mini['imgs'].shape)\n",
    "\n",
    "print(\n",
    "    '|valid| =', len(valid_loader) * config.batch_size,\n",
    ")\n",
    "\n",
    "n_total_iterations = len(valid_loader) * config.n_epochs\n",
    "n_warmup_steps = int(n_total_iterations * config.warmup_ratio)\n",
    "if config.scheduler:\n",
    "    print(\n",
    "        '#total_iters =', n_total_iterations,\n",
    "        '#warmup_iters =', n_warmup_steps,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     #######################################################################################################################################\n",
    "print(config.modality)\n",
    "if config.modality=='text':\n",
    "    model = MultiModalClassifier(config=config)\n",
    "    package = torch.load(config.load_model_path_text)['model']\n",
    "    model.load_state_dict(package)\n",
    "\n",
    "elif config.modality=='img':\n",
    "    model = MultiModalClassifier(config=config)\n",
    "    package = torch.load(config.load_model_path_img)['model']\n",
    "    model.load_state_dict(package)\n",
    "\n",
    "elif config.modality == 'both':\n",
    "    model = MultiModalClassifier(config=config)\n",
    "    package = torch.load(config.load_model_path_both)['model']\n",
    "    model.load_state_dict(package, strict=False) # strict를 함으로서 일부분만 불러오기\n",
    "    ########################       만약 여기서 Bert만 불러오는게 아니라 b_head도 불러온다면?    #########################\n",
    "    # text_backBone = model.BertModel\n",
    "    # config.modality = 'both'\n",
    "    # model = MultiModalClassifier(config=config, backbone = text_backBone).cuda()\n",
    "else:\n",
    "    raise ValueError(\"check config.modality\")\n",
    "\n",
    "# print(model)\n",
    "\n",
    "######### testing 4,23 ##############        \n",
    "minibatch = next(iter(valid_loader))\n",
    "input_ids = minibatch['input_ids']\n",
    "attention_mask = minibatch['attention_mask']\n",
    "imgs = minibatch['imgs']\n",
    "y = minibatch['labels']\n",
    "\n",
    "# b,m,s,d = model(input_ids, attention_mask, imgs)\n",
    "# accuracy1 = (torch.argmax(b, dim=-1) == y[:,0]).sum() / (y[:,0]>=-1).sum().item()\n",
    "# accuracy2 = (torch.argmax(m, dim=-1) == y[:,1]).sum() / (y[:,1]>=-1).sum().item()\n",
    "# accuracy3 = (torch.argmax(s, dim=-1) == y[:,2]).sum() / ((y[:,2]>=-1).sum().item()+1e-06)\n",
    "# accuracy4 = (torch.argmax(d, dim=-1) == y[:,3]).sum() / ((y[:,3]>=-1).sum().item()+1e-06)\n",
    "# print(accuracy1,accuracy2,accuracy3,accuracy4)\n",
    "# print(y)\n",
    "\n",
    "#     # ############# # trainer에 4개 아웃풋 나오는것도 바꿔야함.\n",
    "\n",
    "\n",
    "#     # model_loader = AlbertForSequenceClassification\n",
    "#     # model = model_loader.from_pretrained(\n",
    "#     #     config.pretrained_model_name,\n",
    "#     #     num_labels=config.num_b             # 맨끝에잇는 <cls>token자리에 - layer를 하나 덧붙여줘.\n",
    "#     # )\n",
    "#     '''\n",
    "#      (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
    "#     (pooler_activation): Tanh()\n",
    "#         )\n",
    "#         (dropout): Dropout(p=0.1, inplace=False)\n",
    "#         (classifier): Linear(in_features=768, out_features=57, bias=True)\n",
    "#         )\n",
    "\n",
    "#     '''\n",
    "#     ##############################################################\n",
    "\n",
    "\n",
    "# optimizer = get_optimizer(model, config)\n",
    "\n",
    "# By default, model returns a hidden representation before softmax func.\n",
    "# Thus, we need to use CrossEntropyLoss, which combines LogSoftmax and NLLLoss.\n",
    "crit = nn.CrossEntropyLoss(ignore_index=-2).cuda()\n",
    "\n",
    "\n",
    "if config.gpu_id >= 0:\n",
    "    model.cuda()\n",
    "    crit.cuda()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,m,s,d = model(input_ids.to('cuda'), attention_mask.to(\"cuda\"), imgs.to(\"cuda\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['validation_mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fedfc84f370>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fee16bc5190>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ratio=config.valid_ratio,\n",
    "\n",
    "'''\n",
    "    fn : train_df path\n",
    "    tokenizer : bertTokenizer\n",
    "    img : img path\n",
    "    \n",
    "'''\n",
    "# Get list of labels and list of texts.\n",
    "train_df=pd.read_csv(\"./data/train_df_negOne\")\n",
    "train_df['img_idx'] = train_df.index\n",
    "\n",
    "texts=train_df['product']\n",
    "bcateid = train_df['bcateid']\n",
    "mcateid = train_df['mcateid']\n",
    "scateid = train_df['scateid']\n",
    "dcateid = train_df['dcateid']\n",
    "labels = list(zip(bcateid, mcateid, scateid, dcateid))\n",
    "imgs = train_df['img_idx']\n",
    "\n",
    "shuffled = list(zip(texts, labels, imgs))  # 묶은다음 셔플링.\n",
    "random.shuffle(shuffled)\n",
    "texts = [e[0] for e in shuffled]\n",
    "labels = [e[1] for e in shuffled]\n",
    "imgs = [e[2] for e in shuffled]\n",
    "idx = int(len(texts) * (1 - .2))\n",
    "\n",
    "# Get dataloaders using given tokenizer as collate_fn.\n",
    "train_loader = DataLoader(\n",
    "    ClassificationDataset(texts[:idx], labels[:idx], imgs[:idx], config.img_path),\n",
    "    batch_size= config.batch_size,      ########################################\n",
    "    shuffle=True,\n",
    "    collate_fn=ClassificationCollator(tokenizer, config.max_length), ########################\n",
    ")\n",
    "\n",
    "\n",
    "# train_df.iloc[idx:].to_csv(\"validation.csv\", index=False)\n",
    "valid_loader = DataLoader(\n",
    "    ClassificationDataset(texts[idx:], labels[idx:], imgs[idx:], config.img_path),\n",
    "    batch_size=config.batch_size,       ##########################################\n",
    "    shuffle=False,\n",
    "    collate_fn=ClassificationCollator(tokenizer, config.max_length), #######################\n",
    ")\n",
    "\n",
    "train_loader, valid_loader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/data/kakao/multi/test.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B221.146.21.119/media/data/kakao/multi/test.ipynb#ch0000025vscode-remote?line=0'>1</a>\u001b[0m train_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = pd.read_csv(\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 0, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 2, 2, 0, 2, 0, 2, 1,\n",
       "       1, 1, 0, 3, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 1, 0, 2, 1, 2,\n",
       "       2, 2, 1, 1, 2, 1, 1, 0, 2, 2, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 2, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 0, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1,\n",
       "       1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sum(next(iter(valid_loader))['labels'].numpy() == [[13,12,-2,-2]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(19, 71, 94, -2),\n",
       " (35, 237, 395, 68),\n",
       " (19, 131, 194, -2),\n",
       " (13, 12, 181, -2),\n",
       " (22, 270, 496, -2),\n",
       " (6, 84, 118, -2),\n",
       " (3, 3, 524, -2),\n",
       " (16, 454, 2141, -2),\n",
       " (4, 144, 516, -2),\n",
       " (27, 93, 134, -2),\n",
       " (48, 192, 1561, -2),\n",
       " (17, 314, -2, -2),\n",
       " (2, 2, -2, -2),\n",
       " (13, 12, -2, -2),\n",
       " (34, 343, 1983, -2),\n",
       " (1, 65, 684, 102),\n",
       " (19, 131, 194, -2),\n",
       " (15, 217, 505, -2),\n",
       " (25, 157, 310, 27),\n",
       " (39, 117, 1377, -2),\n",
       " (7, 244, 417, -2),\n",
       " (10, 219, 2816, -2),\n",
       " (8, 76, -2, -2),\n",
       " (36, 166, 1328, -2),\n",
       " (31, 56, 66, -2),\n",
       " (18, 21, -2, -2),\n",
       " (24, 35, 153, -2),\n",
       " (34, 172, 1837, -2),\n",
       " (8, 88, 216, -2),\n",
       " (32, 111, 2136, -2),\n",
       " (10, 180, 2705, -2),\n",
       " (20, 138, 203, -2),\n",
       " (39, 190, 847, -2),\n",
       " (8, 60, 230, -2),\n",
       " (1, 198, 424, -2),\n",
       " (5, 5, 32, 26),\n",
       " (3, 3, 524, -2),\n",
       " (19, 59, 69, -2),\n",
       " (8, 110, -2, -2),\n",
       " (11, 169, 2912, -2),\n",
       " (1, 198, 958, -2),\n",
       " (2, 2, 37, 5),\n",
       " (23, 30, 33, -2),\n",
       " (38, 288, 580, -2),\n",
       " (5, 13, 148, -2),\n",
       " (13, 48, 1381, -2),\n",
       " (43, 136, -2, -2),\n",
       " (26, 210, 1795, -2),\n",
       " (34, 453, -2, -2),\n",
       " (8, 76, 840, -2),\n",
       " (15, 217, -2, -2),\n",
       " (34, 385, 1841, -2),\n",
       " (15, 297, 610, -2),\n",
       " (21, 201, 749, -2),\n",
       " (49, 255, 771, -2),\n",
       " (18, 40, 1413, -2),\n",
       " (11, 10, -2, -2),\n",
       " (10, 9, 344, 111),\n",
       " (5, 5, 32, 3),\n",
       " (10, 14, 16, -2),\n",
       " (22, 238, 426, -2),\n",
       " (10, 215, 857, 74),\n",
       " (41, 376, 1784, -2),\n",
       " (27, 46, 808, -2),\n",
       " (23, 199, 2856, -2),\n",
       " (22, 264, 753, -2),\n",
       " (15, 217, 1298, -2),\n",
       " (1, 206, -2, -2),\n",
       " (9, 475, 2170, -2),\n",
       " (27, 85, -2, -2),\n",
       " (52, 463, 2160, 198),\n",
       " (5, 13, 148, -2),\n",
       " (17, 82, 559, -2),\n",
       " (15, 187, -2, -2),\n",
       " (8, 375, 28, -2),\n",
       " (39, 182, 814, -2),\n",
       " (21, 26, 28, -2),\n",
       " (6, 42, -2, -2),\n",
       " (21, 26, 155, -2),\n",
       " (15, 156, -2, -2),\n",
       " (6, 87, -2, -2),\n",
       " (39, 124, -2, -2),\n",
       " (2, 2, 37, 5),\n",
       " (2, 2, 37, 5),\n",
       " (13, 16, 681, -2),\n",
       " (5, 273, 512, -2),\n",
       " (2, 2, -2, -2),\n",
       " (27, 164, 1596, -2),\n",
       " (8, 60, 724, -2),\n",
       " (8, 66, 86, -2),\n",
       " (10, 150, 1477, -2),\n",
       " (16, 139, -2, -2),\n",
       " (13, 16, 103, 23),\n",
       " (7, 74, 100, -2),\n",
       " (50, 377, 1641, -2),\n",
       " (39, 182, 286, 21),\n",
       " (15, 183, -2, -2),\n",
       " (0, 0, 1056, -2),\n",
       " (16, 36, -2, -2),\n",
       " (18, 40, -2, -2),\n",
       " (11, 109, 490, -2),\n",
       " (35, 78, 472, -2),\n",
       " (0, 479, 2414, -2),\n",
       " (27, 85, 166, -2),\n",
       " (27, 57, 1585, -2),\n",
       " (40, 302, 3068, -2),\n",
       " (23, 30, 33, 4),\n",
       " (16, 454, 2162, -2),\n",
       " (27, 64, 461, -2),\n",
       " (34, 120, 174, -2),\n",
       " (48, 260, 463, -2),\n",
       " (6, 42, 50, -2),\n",
       " (33, 324, 759, -2),\n",
       " (27, 225, 373, -2),\n",
       " (13, 140, 208, -2),\n",
       " (39, 234, 1215, -2),\n",
       " (8, 50, 813, -2),\n",
       " (13, 39, -2, -2),\n",
       " (10, 219, 635, -2),\n",
       " (2, 2, 37, 7),\n",
       " (34, 120, 1035, -2),\n",
       " (27, 85, 696, -2),\n",
       " (52, 463, 2070, 186),\n",
       " (8, 6, -2, -2),\n",
       " (1, 112, 1536, -2),\n",
       " (13, 51, 116, -2),\n",
       " (1, 133, -2, -2),\n",
       " (13, 123, 1032, -2),\n",
       " (1, 22, 405, -2),\n",
       " (1, 65, 420, -2),\n",
       " (15, 217, -2, -2),\n",
       " (8, 50, 59, -2),\n",
       " (52, 463, 2071, 196),\n",
       " (13, 16, 139, 109),\n",
       " (34, 385, 2100, -2),\n",
       " (52, 463, 2113, 200),\n",
       " (19, 71, 124, -2),\n",
       " (17, 82, 114, -2),\n",
       " (16, 278, -2, -2),\n",
       " (49, 255, 1207, -2),\n",
       " (23, 205, 897, -2),\n",
       " (3, 3, 524, -2),\n",
       " (15, 18, 1017, -2),\n",
       " (31, 207, 327, -2),\n",
       " (19, 185, -2, -2),\n",
       " (15, 37, 40, -2),\n",
       " (23, 30, 33, 4),\n",
       " (27, 164, 2351, 276),\n",
       " (16, 19, 21, -2),\n",
       " (8, 50, 59, -2),\n",
       " (44, 181, 758, -2),\n",
       " (7, 208, 328, -2),\n",
       " (8, 110, -2, -2),\n",
       " (4, 32, 35, -2),\n",
       " (19, 131, 194, -2),\n",
       " (31, 322, 754, -2),\n",
       " (29, 142, 742, -2),\n",
       " (2, 2, -2, -2),\n",
       " (13, 140, 208, -2),\n",
       " (8, 38, 643, -2),\n",
       " (15, 18, -2, -2),\n",
       " (33, 438, -2, -2),\n",
       " (38, 97, 1014, -2),\n",
       " (11, 472, 2199, -2),\n",
       " (52, 463, -2, -2),\n",
       " (13, 140, 520, -2),\n",
       " (48, 300, 1785, -2),\n",
       " (10, 15, 120, -2),\n",
       " (52, 463, 2070, -2),\n",
       " (34, 385, 2082, -2),\n",
       " (12, 11, 275, -2),\n",
       " (39, 99, 950, -2),\n",
       " (19, 249, -2, -2),\n",
       " (27, 266, -2, -2),\n",
       " (17, 20, 400, -2),\n",
       " (6, 6, 7, -2),\n",
       " (52, 463, 2097, 204),\n",
       " (15, 465, 2075, -2),\n",
       " (10, 9, 11, -2),\n",
       " (1, 43, 261, -2),\n",
       " (13, 39, 283, -2),\n",
       " (42, 400, 1242, -2),\n",
       " (33, 135, 1141, -2),\n",
       " (11, 325, -2, -2),\n",
       " (8, 60, 313, -2),\n",
       " (33, 290, 1736, -2),\n",
       " (5, 5, 32, 3),\n",
       " (23, 205, -2, -2),\n",
       " (28, 421, 1457, 121),\n",
       " (19, 131, 194, -2),\n",
       " (52, 463, 2070, 194),\n",
       " (14, 284, -2, -2),\n",
       " (49, 200, 1043, -2),\n",
       " (29, 272, -2, -2),\n",
       " (49, 200, 978, -2),\n",
       " (16, 19, 52, -2),\n",
       " (4, 90, -2, -2),\n",
       " (26, 223, 1643, 139),\n",
       " (52, 463, 2194, -2),\n",
       " (0, 374, 1088, -2),\n",
       " (36, 89, 2111, -2),\n",
       " (13, 48, 929, -2),\n",
       " (52, 463, 2070, 194),\n",
       " (14, 396, 1289, -2),\n",
       " (34, 70, 2106, -2),\n",
       " (0, 338, 2174, -2),\n",
       " (5, 5, 32, 3),\n",
       " (23, 72, 962, -2),\n",
       " (19, 52, 128, -2),\n",
       " (29, 142, 2096, -2),\n",
       " (2, 2, 37, -2),\n",
       " (2, 2, -2, -2),\n",
       " (13, 73, 132, -2),\n",
       " (27, 93, -2, -2),\n",
       " (48, 300, 617, -2),\n",
       " (39, 190, 401, -2),\n",
       " (16, 178, 751, -2),\n",
       " (27, 85, 122, -2),\n",
       " (33, 438, -2, -2),\n",
       " (21, 26, -2, -2),\n",
       " (11, 10, -2, -2),\n",
       " (1, 327, 2034, -2),\n",
       " (8, 38, 863, -2),\n",
       " (1, 43, 587, -2),\n",
       " (17, 344, 1273, -2),\n",
       " (6, 87, -2, -2),\n",
       " (6, 42, -2, -2),\n",
       " (10, 219, 357, -2),\n",
       " (2, 2, 37, -2),\n",
       " (21, 26, 121, -2),\n",
       " (38, 229, 1261, -2),\n",
       " (34, 329, 1798, -2),\n",
       " (2, 2, 37, 107),\n",
       " (6, 42, 50, -2),\n",
       " (34, 487, -2, -2),\n",
       " (10, 15, 17, -2),\n",
       " (13, 73, 98, -2),\n",
       " (39, 182, 286, 21),\n",
       " (0, 471, 2102, -2),\n",
       " (16, 139, -2, -2),\n",
       " (8, 88, 389, -2),\n",
       " (5, 29, 96, -2),\n",
       " (43, 461, 2064, -2),\n",
       " (33, 135, -2, -2),\n",
       " (4, 32, 35, -2),\n",
       " (36, 348, 948, -2),\n",
       " (16, 178, 278, 19),\n",
       " (4, 285, 571, -2),\n",
       " (8, 42, 50, -2),\n",
       " (49, 255, 1207, -2),\n",
       " (4, 90, -2, -2),\n",
       " (2, 163, 727, -2),\n",
       " (34, 326, -2, -2),\n",
       " (35, 78, 675, -2),\n",
       " (10, 9, 344, 43),\n",
       " (43, 436, 2152, -2),\n",
       " (33, 135, 1566, -2),\n",
       " (34, 343, 1983, -2),\n",
       " (5, 29, 96, -2),\n",
       " (1, 22, 1132, -2),\n",
       " (40, 101, 1361, -2),\n",
       " (6, 42, 202, -2),\n",
       " (52, 463, 2070, 189),\n",
       " (11, 171, 264, -2),\n",
       " (34, 70, -2, -2),\n",
       " (23, 205, 570, -2),\n",
       " (29, 142, -2, -2),\n",
       " (39, 182, 286, 92),\n",
       " (8, 42, 50, -2),\n",
       " (15, 187, -2, -2),\n",
       " (26, 210, 1083, -2),\n",
       " (10, 222, -2, -2),\n",
       " (15, 187, 888, -2),\n",
       " (13, 140, 296, -2),\n",
       " (16, 55, 1558, -2),\n",
       " (52, 464, 2086, 231),\n",
       " (26, 118, 1884, -2),\n",
       " (15, 183, 1272, -2),\n",
       " (23, 30, 33, 4),\n",
       " (34, 453, 1832, -2),\n",
       " (49, 200, -2, -2),\n",
       " (15, 217, 505, -2),\n",
       " (6, 84, 86, -2),\n",
       " (36, 89, 2142, -2),\n",
       " (34, 172, 825, -2),\n",
       " (8, 110, 802, -2),\n",
       " (15, 183, 288, -2),\n",
       " (23, 30, 33, 4),\n",
       " (27, 196, 309, -2),\n",
       " (19, 131, 194, -2),\n",
       " (21, 26, 257, -2),\n",
       " (26, 369, 1060, 84),\n",
       " (2, 2, 37, -2),\n",
       " (44, 126, -2, -2),\n",
       " (13, 12, 53, -2),\n",
       " (6, 27, 29, -2),\n",
       " (10, 14, -2, -2),\n",
       " (18, 40, 1040, -2),\n",
       " (9, 456, -2, -2),\n",
       " (13, 16, -2, -2),\n",
       " (2, 2, 37, 9),\n",
       " (5, 13, 148, -2),\n",
       " (14, 396, -2, -2),\n",
       " (27, 106, -2, -2),\n",
       " (52, 463, 2113, 203),\n",
       " (8, 66, 118, -2),\n",
       " (2, 2, 51, -2),\n",
       " (5, 5, -2, -2),\n",
       " (10, 47, -2, -2),\n",
       " (42, 108, 154, -2),\n",
       " (49, 200, -2, -2),\n",
       " (15, 37, -2, -2),\n",
       " (27, 93, -2, -2),\n",
       " (4, 32, 35, -2),\n",
       " (2, 2, 37, 7),\n",
       " (23, 205, -2, -2),\n",
       " (16, 139, 205, -2),\n",
       " (20, 188, -2, -2),\n",
       " (50, 377, -2, -2),\n",
       " (29, 226, 1572, -2),\n",
       " (15, 303, 1893, -2),\n",
       " (15, 18, -2, -2),\n",
       " (49, 200, 1043, -2),\n",
       " (39, 190, 1092, -2),\n",
       " (6, 84, -2, -2),\n",
       " (34, 67, 87, -2),\n",
       " (20, 34, 1422, -2),\n",
       " (2, 2, 37, 9),\n",
       " (8, 42, 390, -2),\n",
       " (6, 42, 50, -2),\n",
       " (11, 128, 188, -2),\n",
       " (34, 385, 2085, -2),\n",
       " (27, 164, 1596, -2),\n",
       " (13, 73, 98, -2),\n",
       " (2, 2, 37, 5),\n",
       " (16, 19, 52, -2),\n",
       " (0, 0, 1056, -2),\n",
       " (12, 167, 1692, -2),\n",
       " (23, 30, 33, 4),\n",
       " (24, 35, 235, -2),\n",
       " (13, 39, 319, -2),\n",
       " (15, 183, -2, -2),\n",
       " (27, 85, 122, -2),\n",
       " (21, 26, 257, -2),\n",
       " (8, 42, -2, -2),\n",
       " (33, 261, 1857, -2),\n",
       " (2, 2, 37, 7),\n",
       " (10, 492, 2282, 220),\n",
       " (5, 5, 32, 3),\n",
       " (20, 188, 1733, -2),\n",
       " (26, 210, 2927, -2),\n",
       " (19, 131, 2564, -2),\n",
       " (49, 200, 317, -2),\n",
       " (10, 14, 16, -2),\n",
       " (10, 9, 344, 30),\n",
       " (33, 135, 1141, -2),\n",
       " (16, 55, 182, -2),\n",
       " (49, 255, 1324, -2),\n",
       " (24, 176, 1319, -2),\n",
       " (2, 2, 51, -2),\n",
       " (22, 227, -2, -2),\n",
       " (15, 37, 2445, -2),\n",
       " (27, 388, 1854, -2),\n",
       " (33, 380, 1326, -2),\n",
       " (10, 15, 17, -2),\n",
       " (10, 9, -2, -2),\n",
       " (31, 56, 260, -2),\n",
       " (23, 203, -2, -2),\n",
       " (6, 202, -2, -2),\n",
       " (24, 31, 42, -2),\n",
       " (43, 174, 2374, -2),\n",
       " (27, 164, 253, -2),\n",
       " (33, 438, 2177, -2),\n",
       " (33, 246, 422, -2),\n",
       " (19, 357, 996, -2),\n",
       " (9, 456, 1975, -2),\n",
       " (2, 2, 37, 5),\n",
       " (7, 244, 892, -2),\n",
       " (19, 23, 353, -2),\n",
       " (15, 217, 347, -2),\n",
       " (23, 30, 33, 4),\n",
       " (20, 34, 1422, -2),\n",
       " (23, 205, 897, -2),\n",
       " (4, 144, 217, -2),\n",
       " (7, 179, 2679, -2),\n",
       " (29, 280, 1550, -2),\n",
       " (49, 200, 1043, -2),\n",
       " (13, 16, -2, -2),\n",
       " (29, 272, -2, -2),\n",
       " (33, 438, -2, -2),\n",
       " (33, 261, -2, -2),\n",
       " (23, 98, 140, -2),\n",
       " (1, 198, -2, -2),\n",
       " (10, 14, -2, -2),\n",
       " (20, 34, -2, -2),\n",
       " (43, 365, 1238, -2),\n",
       " (13, 51, 116, -2),\n",
       " (9, 235, 1957, -2),\n",
       " (50, 333, 921, -2),\n",
       " (27, 106, 250, -2),\n",
       " (7, 79, -2, -2),\n",
       " (10, 222, 364, -2),\n",
       " (19, 59, 187, -2),\n",
       " (1, 198, 1479, -2),\n",
       " (6, 27, 1308, -2),\n",
       " (33, 261, 1144, -2),\n",
       " (13, 250, 438, -2),\n",
       " (39, 234, -2, -2),\n",
       " (15, 257, 1087, -2),\n",
       " (35, 134, -2, -2),\n",
       " (32, 111, 954, -2),\n",
       " (34, 385, 2124, -2),\n",
       " (22, 378, 1342, -2),\n",
       " (49, 200, -2, -2),\n",
       " (26, 223, 2458, -2),\n",
       " (22, 287, 1436, -2),\n",
       " (49, 255, -2, -2),\n",
       " (34, 172, -2, -2),\n",
       " (52, 463, 2070, 194),\n",
       " (24, 434, -2, -2),\n",
       " (2, 2, 37, 5),\n",
       " (0, 0, 211, -2),\n",
       " (34, 172, -2, -2),\n",
       " (10, 9, 11, -2),\n",
       " (1, 206, -2, -2),\n",
       " (5, 5, 6, 13),\n",
       " (26, 83, -2, -2),\n",
       " (2, 2, 37, -2),\n",
       " (16, 139, 204, -2),\n",
       " (39, 182, 683, -2),\n",
       " (5, 5, 32, 3),\n",
       " (29, 272, 1020, -2),\n",
       " (26, 223, 1720, -2),\n",
       " (36, 158, 237, -2),\n",
       " (19, 59, -2, -2),\n",
       " (2, 2, 374, -2),\n",
       " (4, 4, 560, -2),\n",
       " (12, 11, 275, -2),\n",
       " (39, 124, 1223, -2),\n",
       " (23, 199, 1221, -2),\n",
       " (34, 172, -2, -2),\n",
       " (21, 241, 822, -2),\n",
       " (38, 168, 258, -2),\n",
       " (33, 246, 422, -2),\n",
       " (2, 2, 37, 5),\n",
       " (1, 65, 84, -2),\n",
       " (27, 164, 530, -2),\n",
       " (0, 115, -2, -2),\n",
       " (10, 215, 2409, -2),\n",
       " (23, 254, -2, -2),\n",
       " (2, 2, 37, 9),\n",
       " (11, 152, 2139, -2),\n",
       " (10, 492, 2314, -2),\n",
       " (50, 446, 1775, -2),\n",
       " (5, 5, 6, 13),\n",
       " (52, 463, 2070, 189),\n",
       " (27, 93, 980, -2),\n",
       " (19, 59, -2, -2),\n",
       " (21, 26, 715, -2),\n",
       " (7, 7, -2, -2),\n",
       " (1, 65, 420, -2),\n",
       " (11, 92, -2, -2),\n",
       " (32, 373, 1776, -2),\n",
       " (5, 13, 185, -2),\n",
       " (43, 350, 957, -2),\n",
       " (16, 19, 21, -2),\n",
       " (27, 388, 2207, -2),\n",
       " (10, 14, -2, -2),\n",
       " (2, 2, 37, 7),\n",
       " (13, 12, 135, -2),\n",
       " (27, 164, 525, -2),\n",
       " (47, 263, 468, -2),\n",
       " (6, 87, 396, -2),\n",
       " (42, 214, 335, -2),\n",
       " (13, 252, -2, -2),\n",
       " (13, 73, 98, -2),\n",
       " (19, 131, 194, -2),\n",
       " (52, 463, -2, -2),\n",
       " (40, 368, 1059, -2),\n",
       " (16, 339, 911, -2),\n",
       " (39, 99, -2, -2),\n",
       " (10, 492, -2, -2),\n",
       " (8, 60, 230, -2),\n",
       " (50, 473, 2329, -2),\n",
       " (4, 90, 157, 14),\n",
       " (19, 131, 194, -2),\n",
       " (35, 212, 332, -2),\n",
       " (4, 275, 516, -2),\n",
       " (23, 205, 323, -2),\n",
       " (13, 12, 135, -2),\n",
       " (43, 116, 168, -2),\n",
       " (49, 200, -2, -2),\n",
       " (13, 140, 208, -2),\n",
       " (34, 67, -2, -2),\n",
       " (19, 119, 1476, -2),\n",
       " (35, 212, 332, -2),\n",
       " (0, 115, 1465, -2),\n",
       " (16, 36, -2, -2),\n",
       " (15, 187, 1555, -2),\n",
       " (6, 84, 457, -2),\n",
       " (17, 236, 392, -2),\n",
       " (48, 300, 617, -2),\n",
       " (16, 19, 52, -2),\n",
       " (4, 32, 35, -2),\n",
       " (13, 16, 103, 23),\n",
       " (17, 82, 559, -2),\n",
       " (13, 39, 731, -2),\n",
       " (15, 183, 1272, -2),\n",
       " (21, 201, 749, -2),\n",
       " (27, 57, -2, -2),\n",
       " (15, 303, 775, -2),\n",
       " (16, 62, 75, -2),\n",
       " (0, 191, 303, -2),\n",
       " (1, 22, 24, -2),\n",
       " (8, 42, -2, -2),\n",
       " (12, 122, 177, 65),\n",
       " (34, 172, -2, -2),\n",
       " (12, 100, 142, -2),\n",
       " (27, 93, 600, -2),\n",
       " (13, 12, 53, -2),\n",
       " (27, 93, -2, -2),\n",
       " (7, 79, 994, -2),\n",
       " (25, 277, 528, -2),\n",
       " (52, 463, 2160, 198),\n",
       " (22, 264, -2, -2),\n",
       " (36, 155, -2, -2),\n",
       " (34, 496, 2635, -2),\n",
       " (19, 23, 366, -2),\n",
       " (8, 6, 171, -2),\n",
       " (19, 59, 69, -2),\n",
       " (44, 162, 1162, -2),\n",
       " (34, 487, -2, -2),\n",
       " (34, 91, -2, -2),\n",
       " (16, 55, 182, -2),\n",
       " (8, 6, 9, -2),\n",
       " (19, 131, 598, -2),\n",
       " (8, 6, 88, -2),\n",
       " (13, 12, 53, -2),\n",
       " (16, 139, 326, -2),\n",
       " (27, 57, 1115, -2),\n",
       " (1, 65, 420, -2),\n",
       " (13, 250, 438, -2),\n",
       " (6, 87, 252, -2),\n",
       " (4, 90, 129, -2),\n",
       " (19, 119, 1632, -2),\n",
       " (2, 529, -2, -2),\n",
       " (2, 2, -2, -2),\n",
       " (8, 232, 384, -2),\n",
       " (5, 13, 148, -2),\n",
       " (7, 74, 100, -2),\n",
       " (16, 139, 204, -2),\n",
       " (34, 326, 784, -2),\n",
       " (21, 26, 45, -2),\n",
       " (8, 60, 230, -2),\n",
       " (5, 13, 148, -2),\n",
       " (13, 231, -2, -2),\n",
       " (23, 98, 1291, -2),\n",
       " (43, 436, 2152, -2),\n",
       " (34, 329, 1294, -2),\n",
       " (34, 453, 2112, -2),\n",
       " (13, 16, 18, -2),\n",
       " (23, 30, 33, 185),\n",
       " (6, 87, 465, -2),\n",
       " (34, 70, -2, -2),\n",
       " (15, 303, -2, -2),\n",
       " (19, 131, 598, -2),\n",
       " (10, 492, -2, -2),\n",
       " (27, 75, 1898, -2),\n",
       " (38, 259, 861, -2),\n",
       " (23, 205, -2, -2),\n",
       " (34, 383, 2617, -2),\n",
       " (36, 276, -2, -2),\n",
       " (36, 155, 2390, -2),\n",
       " (13, 123, 356, -2),\n",
       " (27, 64, 81, -2),\n",
       " (9, 355, 1740, -2),\n",
       " (10, 9, 11, -2),\n",
       " (8, 42, 390, -2),\n",
       " (8, 76, 105, -2),\n",
       " (39, 182, 683, -2),\n",
       " (16, 139, 204, -2),\n",
       " (4, 63, 79, -2),\n",
       " (4, 275, 732, -2),\n",
       " (10, 14, 16, -2),\n",
       " (44, 162, 245, -2),\n",
       " (15, 187, 888, -2),\n",
       " (6, 6, 548, -2),\n",
       " (5, 428, -2, -2),\n",
       " (16, 454, 2162, -2),\n",
       " (27, 64, 1135, -2),\n",
       " (4, 63, 79, -2),\n",
       " (55, 531, 2803, -2),\n",
       " (19, 131, -2, -2),\n",
       " (13, 12, 74, -2),\n",
       " (49, 200, 1176, -2),\n",
       " (8, 50, 59, -2),\n",
       " (10, 222, -2, -2),\n",
       " (21, 26, 155, -2),\n",
       " (33, 438, 2404, -2),\n",
       " (12, 151, 3162, -2),\n",
       " (11, 10, 1662, -2),\n",
       " (19, 131, -2, -2),\n",
       " (13, 48, 58, -2),\n",
       " (23, 205, 323, -2),\n",
       " (13, 12, -2, -2),\n",
       " (2, 2, 37, 7),\n",
       " (33, 408, 2331, -2),\n",
       " (6, 202, 80, -2),\n",
       " (29, 142, 2183, -2),\n",
       " (19, 185, 292, -2),\n",
       " (16, 62, 874, -2),\n",
       " (15, 183, 288, -2),\n",
       " (33, 261, 1144, -2),\n",
       " (4, 271, 510, -2),\n",
       " (40, 127, 1322, -2),\n",
       " (29, 194, 1195, -2),\n",
       " (15, 18, 20, -2),\n",
       " (0, 497, 2475, -2),\n",
       " (36, 166, 255, -2),\n",
       " (15, 187, 985, -2),\n",
       " (27, 64, -2, -2),\n",
       " (6, 84, 789, -2),\n",
       " (36, 158, 237, -2),\n",
       " (34, 453, 2112, -2),\n",
       " (49, 200, 1043, -2),\n",
       " (12, 100, 1738, -2),\n",
       " (8, 42, 202, -2),\n",
       " (38, 209, 329, -2),\n",
       " (34, 70, 92, -2),\n",
       " (17, 82, -2, -2),\n",
       " (2, 2, 37, -2),\n",
       " (10, 9, 11, -2),\n",
       " (6, 6, 171, -2),\n",
       " (49, 200, 1176, -2),\n",
       " (4, 32, 35, -2),\n",
       " (39, 99, 950, -2),\n",
       " (26, 83, -2, -2),\n",
       " (2, 2, 37, -2),\n",
       " (34, 172, 265, -2),\n",
       " (29, 272, 1184, -2),\n",
       " (4, 275, 732, -2),\n",
       " (19, 131, 194, -2),\n",
       " (48, 300, 1296, -2),\n",
       " (20, 188, -2, -2),\n",
       " (42, 108, 154, -2),\n",
       " (16, 139, 704, -2),\n",
       " (12, 11, 212, -2),\n",
       " (8, 38, 41, -2),\n",
       " (18, 107, 151, -2),\n",
       " (8, 6, 171, -2),\n",
       " (13, 16, 117, -2),\n",
       " (15, 183, -2, -2),\n",
       " (23, 205, 323, -2),\n",
       " (38, 97, 1151, -2),\n",
       " (23, 30, 33, -2),\n",
       " (8, 42, 575, -2),\n",
       " (15, 297, -2, -2),\n",
       " (21, 201, 1067, -2),\n",
       " (0, 115, -2, -2),\n",
       " (42, 214, 335, -2),\n",
       " (17, 82, 249, -2),\n",
       " (5, 13, 148, -2),\n",
       " (4, 4, 819, -2),\n",
       " (21, 154, 287, -2),\n",
       " (11, 109, 490, -2),\n",
       " (13, 16, 350, -2),\n",
       " (21, 201, 318, -2),\n",
       " (27, 93, 701, -2),\n",
       " (2, 2, 51, -2),\n",
       " (2, 2, 37, -2),\n",
       " (17, 20, 427, -2),\n",
       " (8, 375, -2, -2),\n",
       " (10, 47, 1554, -2),\n",
       " (17, 41, 325, -2),\n",
       " (16, 454, 2162, -2),\n",
       " (16, 55, 182, -2),\n",
       " (15, 156, 233, -2),\n",
       " (23, 30, 33, -2),\n",
       " (15, 156, 583, -2),\n",
       " (1, 206, 324, -2),\n",
       " (21, 26, 45, -2),\n",
       " (2, 2, 374, -2),\n",
       " (16, 178, 751, -2),\n",
       " (17, 41, 750, -2),\n",
       " (50, 239, 404, -2),\n",
       " (27, 225, 1666, -2),\n",
       " (54, 511, 2471, -2),\n",
       " (13, 16, 139, 12),\n",
       " (5, 5, 32, 26),\n",
       " (13, 12, 53, -2),\n",
       " (10, 397, 1509, -2),\n",
       " (15, 187, 744, -2),\n",
       " (13, 12, -2, -2),\n",
       " (8, 6, 9, -2),\n",
       " (21, 26, 121, -2),\n",
       " (48, 300, 617, -2),\n",
       " (33, 261, 745, -2),\n",
       " (2, 2, 37, -2),\n",
       " (16, 36, -2, -2),\n",
       " (2, 163, 606, -2),\n",
       " (27, 93, 746, -2),\n",
       " (19, 23, 25, -2),\n",
       " (33, 291, -2, -2),\n",
       " (27, 85, -2, -2),\n",
       " (14, 170, 263, -2),\n",
       " (13, 73, -2, -2),\n",
       " (49, 200, -2, -2),\n",
       " (11, 169, 562, -2),\n",
       " (47, 381, 1979, -2),\n",
       " (39, 99, 1763, -2),\n",
       " (55, 494, -2, -2),\n",
       " (23, 205, 323, -2),\n",
       " (5, 13, 148, -2),\n",
       " (27, 46, 240, -2),\n",
       " (52, 463, 2070, 194),\n",
       " (10, 416, 1405, -2),\n",
       " (13, 12, 74, -2),\n",
       " (31, 56, 379, -2),\n",
       " (8, 6, 801, -2),\n",
       " (5, 273, 691, -2),\n",
       " (8, 50, 667, -2),\n",
       " (34, 383, 2271, -2),\n",
       " (1, 133, 195, -2),\n",
       " (26, 44, 54, 116),\n",
       " (19, 185, 543, -2),\n",
       " (9, 475, 2215, -2),\n",
       " (15, 303, 775, -2),\n",
       " (23, 30, 33, 4),\n",
       " (19, 185, -2, -2),\n",
       " (13, 250, 438, -2),\n",
       " (8, 6, -2, -2),\n",
       " (12, 151, 227, -2),\n",
       " (0, 191, 303, -2),\n",
       " (10, 222, 364, -2),\n",
       " (39, 182, -2, -2),\n",
       " (6, 42, 99, -2),\n",
       " (2, 2, 37, 7),\n",
       " (27, 164, 530, -2),\n",
       " (23, 72, 435, -2),\n",
       " (27, 93, 134, -2),\n",
       " (15, 257, 1204, -2),\n",
       " (7, 244, 892, -2),\n",
       " (13, 51, 116, -2),\n",
       " (1, 133, 195, -2),\n",
       " (13, 123, -2, -2),\n",
       " (33, 261, 466, -2),\n",
       " (27, 85, 122, -2),\n",
       " (15, 297, 710, -2),\n",
       " (36, 89, 2120, -2),\n",
       " (0, 115, 167, -2),\n",
       " (16, 55, 64, -2),\n",
       " (43, 436, -2, -2),\n",
       " (5, 13, 148, -2),\n",
       " (4, 32, 35, -2),\n",
       " (2, 2, 37, 7),\n",
       " (49, 200, -2, -2),\n",
       " (2, 2, 3, -2),\n",
       " (12, 11, 275, -2),\n",
       " (15, 465, -2, -2),\n",
       " (8, 50, 59, -2),\n",
       " (15, 187, 603, -2),\n",
       " (23, 30, 33, -2),\n",
       " (19, 131, -2, -2),\n",
       " (50, 448, -2, -2),\n",
       " (26, 366, 1732, -2),\n",
       " (26, 44, 1323, -2),\n",
       " (13, 12, 53, -2),\n",
       " (10, 150, 1477, -2),\n",
       " (53, 466, 2081, -2),\n",
       " (34, 329, 1294, -2),\n",
       " (39, 99, 1763, -2),\n",
       " (23, 205, 323, -2),\n",
       " (13, 73, -2, -2),\n",
       " (13, 250, 438, -2),\n",
       " (48, 260, 1286, -2),\n",
       " (19, 160, -2, -2),\n",
       " (15, 221, 1156, -2),\n",
       " (15, 183, -2, -2),\n",
       " (8, 375, 715, -2),\n",
       " (5, 13, 148, -2),\n",
       " (13, 252, 969, -2),\n",
       " (16, 19, 52, -2),\n",
       " (15, 257, -2, -2),\n",
       " (21, 201, 318, -2),\n",
       " (15, 68, -2, -2),\n",
       " (17, 82, 249, -2),\n",
       " (10, 14, 267, -2),\n",
       " (33, 438, -2, -2),\n",
       " (12, 167, 569, -2),\n",
       " (16, 139, 204, -2),\n",
       " (1, 133, 195, -2),\n",
       " (8, 88, 216, -2),\n",
       " (1, 43, 533, -2),\n",
       " (52, 463, 2070, 189),\n",
       " (19, 52, 532, -2),\n",
       " (27, 57, 78, -2),\n",
       " (29, 272, 511, -2),\n",
       " (49, 255, 1207, -2),\n",
       " (2, 2, -2, -2),\n",
       " (5, 5, 32, 3),\n",
       " (44, 126, 184, -2),\n",
       " (8, 60, 314, -2),\n",
       " (34, 326, -2, -2),\n",
       " (13, 39, 43, -2),\n",
       " (23, 205, 323, -2),\n",
       " (15, 257, 1204, -2),\n",
       " (26, 336, 1412, -2),\n",
       " (15, 217, -2, -2),\n",
       " (2, 2, 37, 107),\n",
       " (52, 463, 2113, 203),\n",
       " (17, 82, 249, -2),\n",
       " (33, 405, 2385, -2),\n",
       " (34, 326, 2090, -2),\n",
       " (15, 183, -2, -2),\n",
       " (19, 131, 194, -2),\n",
       " (8, 66, -2, -2),\n",
       " (9, 8, 1081, -2),\n",
       " (2, 163, 1360, -2),\n",
       " (4, 63, 239, -2),\n",
       " (15, 303, -2, -2),\n",
       " (18, 40, -2, -2),\n",
       " (15, 187, 603, -2),\n",
       " (27, 106, -2, -2),\n",
       " (23, 30, 33, 4),\n",
       " (1, 198, -2, -2),\n",
       " (12, 292, -2, -2),\n",
       " (19, 71, 124, -2),\n",
       " (33, 261, 645, -2),\n",
       " (2, 2, 374, -2),\n",
       " (3, 3, -2, -2),\n",
       " (34, 383, 1163, -2),\n",
       " (15, 221, 792, -2),\n",
       " (49, 200, -2, -2),\n",
       " (5, 5, 32, 3),\n",
       " (23, 205, -2, -2),\n",
       " (11, 233, 419, 39),\n",
       " (42, 441, -2, -2),\n",
       " (20, 188, -2, -2),\n",
       " (1, 206, 324, -2),\n",
       " (13, 12, 74, -2),\n",
       " (9, 235, 2043, -2),\n",
       " (7, 213, 666, -2),\n",
       " (48, 192, 1561, -2),\n",
       " (11, 10, 282, -2),\n",
       " (13, 12, 135, -2),\n",
       " (10, 14, -2, -2),\n",
       " (9, 475, 2212, -2),\n",
       " (24, 31, 42, -2),\n",
       " (27, 164, 506, -2),\n",
       " (16, 62, 773, -2),\n",
       " (2, 2, 37, -2),\n",
       " (2, 2, 37, 7),\n",
       " (5, 13, 148, -2),\n",
       " (16, 178, 278, -2),\n",
       " (16, 139, 204, -2),\n",
       " (2, 2, -2, -2),\n",
       " (48, 192, 305, -2),\n",
       " (20, 34, -2, -2),\n",
       " (49, 200, -2, -2),\n",
       " (10, 9, 11, -2),\n",
       " (27, 46, 808, -2),\n",
       " (13, 140, 208, -2),\n",
       " (8, 42, 202, -2),\n",
       " (34, 343, 1855, -2),\n",
       " (19, 160, -2, -2),\n",
       " (21, 25, 1778, -2),\n",
       " (40, 127, 186, -2),\n",
       " (1, 133, 195, -2),\n",
       " (10, 14, 267, -2),\n",
       " (27, 93, 976, -2),\n",
       " (8, 66, 86, -2),\n",
       " (48, 300, 1785, -2),\n",
       " (34, 172, 825, -2),\n",
       " (34, 343, 1983, -2),\n",
       " (39, 234, 1469, -2),\n",
       " (7, 79, 795, -2),\n",
       " (8, 42, 50, -2),\n",
       " (8, 6, 88, -2),\n",
       " (27, 247, -2, -2),\n",
       " (34, 385, 2327, -2),\n",
       " (26, 384, 1994, -2),\n",
       " (43, 116, -2, -2),\n",
       " (8, 6, 618, -2),\n",
       " (16, 19, 21, -2),\n",
       " (1, 198, 964, -2),\n",
       " (49, 255, -2, -2),\n",
       " (19, 59, -2, -2),\n",
       " (8, 6, 88, -2),\n",
       " (31, 56, 66, -2),\n",
       " (13, 12, 74, -2),\n",
       " (23, 205, -2, -2),\n",
       " (16, 19, 21, -2),\n",
       " (9, 475, 2215, -2),\n",
       " (20, 34, 38, -2),\n",
       " (42, 356, -2, -2),\n",
       " (2, 2, 37, 7),\n",
       " (19, 131, -2, -2),\n",
       " (50, 377, -2, -2),\n",
       " (8, 66, 936, -2),\n",
       " (44, 162, 245, -2),\n",
       " (27, 106, 250, -2),\n",
       " (15, 156, -2, -2),\n",
       " (15, 37, -2, -2),\n",
       " (1, 133, 195, -2),\n",
       " (13, 12, 53, -2),\n",
       " (11, 109, -2, -2),\n",
       " (13, 16, -2, -2),\n",
       " (23, 30, 33, 4),\n",
       " (6, 42, 202, -2),\n",
       " (2, 2, 37, 9),\n",
       " (21, 154, 287, -2),\n",
       " (6, 42, 202, -2),\n",
       " (22, 287, 577, -2),\n",
       " (8, 42, -2, -2),\n",
       " (8, 38, -2, -2),\n",
       " (6, 42, 99, -2),\n",
       " (8, 6, 602, -2),\n",
       " (26, 283, 556, -2),\n",
       " (52, 463, 2071, 196),\n",
       " (5, 13, -2, -2),\n",
       " (5, 13, -2, -2),\n",
       " (34, 383, 2271, -2),\n",
       " (16, 454, 2214, -2),\n",
       " (15, 156, -2, -2),\n",
       " (35, 130, 193, -2),\n",
       " (5, 5, 32, 18),\n",
       " (19, 59, 187, -2),\n",
       " (34, 383, 2271, -2),\n",
       " (15, 257, 1204, -2),\n",
       " (0, 0, 1, -2),\n",
       " (8, 66, 118, -2),\n",
       " (37, 95, 136, -2),\n",
       " (5, 13, -2, -2),\n",
       " (15, 297, 610, -2),\n",
       " (49, 200, 907, -2),\n",
       " (10, 14, -2, -2),\n",
       " (16, 62, 75, -2),\n",
       " (16, 178, 278, 40),\n",
       " (5, 5, 421, -2),\n",
       " (19, 52, 128, -2),\n",
       " (27, 93, 980, -2),\n",
       " (23, 205, 323, -2),\n",
       " (34, 326, 2090, -2),\n",
       " (39, 182, -2, -2),\n",
       " (13, 140, 296, -2),\n",
       " (5, 5, 32, 3),\n",
       " (0, 338, 2184, -2),\n",
       " (14, 81, 113, -2),\n",
       " (33, 291, -2, -2),\n",
       " (1, 198, 1118, -2),\n",
       " (13, 137, 1003, -2),\n",
       " (17, 82, 114, -2),\n",
       " (42, 214, 1064, 136),\n",
       " (50, 239, 998, -2),\n",
       " (28, 49, -2, -2),\n",
       " (40, 248, 1939, -2),\n",
       " (8, 110, 396, -2),\n",
       " (27, 164, -2, -2),\n",
       " (15, 304, -2, -2),\n",
       " (32, 268, 491, -2),\n",
       " (17, 121, 835, -2),\n",
       " (15, 183, -2, -2),\n",
       " (23, 30, 33, 4),\n",
       " (21, 26, 121, -2),\n",
       " (2, 2, -2, -2),\n",
       " (2, 2, 37, -2),\n",
       " (34, 354, -2, -2),\n",
       " (36, 89, 2200, -2),\n",
       " (23, 203, 432, -2),\n",
       " (26, 223, 2840, -2),\n",
       " (5, 230, 503, -2),\n",
       " (12, 11, 275, -2),\n",
       " (31, 296, 1396, -2),\n",
       " (43, 116, 2179, -2),\n",
       " (6, 42, 99, -2),\n",
       " (33, 438, -2, -2),\n",
       " (36, 348, 1516, -2),\n",
       " (13, 39, 43, -2),\n",
       " (8, 88, 1000, -2),\n",
       " (2, 2, -2, -2),\n",
       " (8, 42, 390, -2),\n",
       " (8, 488, -2, -2),\n",
       " (48, 192, 1561, -2),\n",
       " (1, 206, -2, -2),\n",
       " (54, 511, 2471, -2),\n",
       " (13, 12, 14, -2),\n",
       " (23, 199, 453, -2),\n",
       " (6, 27, -2, -2),\n",
       " (5, 230, 1122, -2),\n",
       " (52, 463, 2071, 211),\n",
       " (27, 225, 373, -2),\n",
       " (7, 7, -2, -2),\n",
       " (6, 84, 118, -2),\n",
       " (13, 16, 103, 11),\n",
       " (26, 118, 1813, -2),\n",
       " (23, 30, 33, 4),\n",
       " (15, 508, -2, -2),\n",
       " (17, 82, 114, -2),\n",
       " (13, 48, 1381, -2),\n",
       " (16, 55, 182, -2),\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>product</th>\n",
       "      <th>bcateid</th>\n",
       "      <th>mcateid</th>\n",
       "      <th>scateid</th>\n",
       "      <th>dcateid</th>\n",
       "      <th>img_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X3992887813</td>\n",
       "      <td>덱케 O史：O DE1H9ABG052WSMT</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>6507854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H4214973612</td>\n",
       "      <td>화미 황엿 ( 소 ) 3kg x 5</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>1323</td>\n",
       "      <td>-2</td>\n",
       "      <td>6507855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I4580515344</td>\n",
       "      <td>[글로벌샵]독일 Nutreov Capileov Double Action Anti-H...</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>-2</td>\n",
       "      <td>6507856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O4211452195</td>\n",
       "      <td>아디다스 CE9026 CE9036 CV3997 CV3988 트레이닝 세트</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>49</td>\n",
       "      <td>-2</td>\n",
       "      <td>6507857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O4669409313</td>\n",
       "      <td>삐까 펄 중지갑 여성지갑 지갑 여성중지갑 손지갑 여</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>103</td>\n",
       "      <td>41</td>\n",
       "      <td>6507858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626959</th>\n",
       "      <td>T4336486181</td>\n",
       "      <td>스킨다임 핸드크림 피치향(60g)핸드로션 면세점 입점</td>\n",
       "      <td>36</td>\n",
       "      <td>348</td>\n",
       "      <td>948</td>\n",
       "      <td>-2</td>\n",
       "      <td>8134813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626960</th>\n",
       "      <td>X4551630682</td>\n",
       "      <td>옥상트랩(하수구용 옥상 트랩)사이즈_100파이</td>\n",
       "      <td>39</td>\n",
       "      <td>99</td>\n",
       "      <td>1929</td>\n",
       "      <td>-2</td>\n",
       "      <td>8134814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626961</th>\n",
       "      <td>P4506131881</td>\n",
       "      <td>[KB 5% 청구할인]소야 아름 사각종지 (5컬러) 사각종지 종지 여주도자</td>\n",
       "      <td>15</td>\n",
       "      <td>37</td>\n",
       "      <td>1419</td>\n",
       "      <td>-2</td>\n",
       "      <td>8134815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626962</th>\n",
       "      <td>G4716723552</td>\n",
       "      <td>모서리안전보호대 대 브라운 2M   유아안전 아이</td>\n",
       "      <td>22</td>\n",
       "      <td>424</td>\n",
       "      <td>2193</td>\n",
       "      <td>-2</td>\n",
       "      <td>8134816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626963</th>\n",
       "      <td>I4430549534</td>\n",
       "      <td>쉬바 7세 촉촉한 닭가슴살 in 그레이비 캔 85g x 24</td>\n",
       "      <td>49</td>\n",
       "      <td>255</td>\n",
       "      <td>1207</td>\n",
       "      <td>-2</td>\n",
       "      <td>8134817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1626964 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pid                                            product  \\\n",
       "0        X3992887813                            덱케 O史：O DE1H9ABG052WSMT   \n",
       "1        H4214973612                                화미 황엿 ( 소 ) 3kg x 5   \n",
       "2        I4580515344  [글로벌샵]독일 Nutreov Capileov Double Action Anti-H...   \n",
       "3        O4211452195           아디다스 CE9026 CE9036 CV3997 CV3988 트레이닝 세트   \n",
       "4        O4669409313                       삐까 펄 중지갑 여성지갑 지갑 여성중지갑 손지갑 여   \n",
       "...              ...                                                ...   \n",
       "1626959  T4336486181                      스킨다임 핸드크림 피치향(60g)핸드로션 면세점 입점   \n",
       "1626960  X4551630682                          옥상트랩(하수구용 옥상 트랩)사이즈_100파이   \n",
       "1626961  P4506131881          [KB 5% 청구할인]소야 아름 사각종지 (5컬러) 사각종지 종지 여주도자   \n",
       "1626962  G4716723552                        모서리안전보호대 대 브라운 2M   유아안전 아이   \n",
       "1626963  I4430549534                  쉬바 7세 촉촉한 닭가슴살 in 그레이비 캔 85g x 24   \n",
       "\n",
       "         bcateid  mcateid  scateid  dcateid  img_idx  \n",
       "0             13       12       -2       -2  6507854  \n",
       "1             26       44     1323       -2  6507855  \n",
       "2              8       50       59       -2  6507856  \n",
       "3              5        5       49       -2  6507857  \n",
       "4             13       16      103       41  6507858  \n",
       "...          ...      ...      ...      ...      ...  \n",
       "1626959       36      348      948       -2  8134813  \n",
       "1626960       39       99     1929       -2  8134814  \n",
       "1626961       15       37     1419       -2  8134815  \n",
       "1626962       22      424     2193       -2  8134816  \n",
       "1626963       49      255     1207       -2  8134817  \n",
       "\n",
       "[1626964 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  10,   15,   17,   -2],\n",
       "        [  13,  141,  210,   -2],\n",
       "        [  17,   20,   22,   -2],\n",
       "        [  12,  151, 1104,   -2],\n",
       "        [   8,    6,    9,   -2],\n",
       "        [  16,  454, 2162,   -2],\n",
       "        [   7,   79,  394,   -2],\n",
       "        [  16,  178,  751,   -2],\n",
       "        [  16,   55,  182,   -2],\n",
       "        [  27,   93,  757,   -2],\n",
       "        [  34,  326,  784,   -2],\n",
       "        [  13,  250,  438,   -2],\n",
       "        [   8,  110,   -2,   -2],\n",
       "        [  13,   48,   58,   -2],\n",
       "        [  52,  463,   -2,   -2],\n",
       "        [   5,    5,   49,   -2],\n",
       "        [  15,   68,   89,   -2],\n",
       "        [  15,  221,  360,   -2],\n",
       "        [  10,  219,  357,   -2],\n",
       "        [  13,   12,  234,   -2],\n",
       "        [  12,   11,  251,   -2],\n",
       "        [  27,   64,   93,   -2],\n",
       "        [  10,  180,   -2,   -2],\n",
       "        [  52,  463, 2113,  191],\n",
       "        [  27,   57,  649,   -2],\n",
       "        [  17,   82,  249,   -2],\n",
       "        [  50,  239,  604,   79],\n",
       "        [  38,   97,  639,   -2],\n",
       "        [  49,  255,   -2,   -2],\n",
       "        [   5,    5,    6,    1],\n",
       "        [   8,   60,   -2,   -2],\n",
       "        [  27,   75,   -2,   -2],\n",
       "        [  21,   26,  155,   -2],\n",
       "        [   4,  144,  217,   -2],\n",
       "        [  27,   93,   -2,   -2],\n",
       "        [   8,   50,   59,   -2],\n",
       "        [  34,  453, 2112,   -2],\n",
       "        [  19,  131,  194,   -2],\n",
       "        [  50,  473, 2329,   -2],\n",
       "        [   1,  206,  324,   -2],\n",
       "        [  34,  453, 1832,   -2],\n",
       "        [  50,  402, 1456,  120],\n",
       "        [  13,   12,   -2,   -2],\n",
       "        [  34,  385, 2266,   -2],\n",
       "        [   2,    2,   51,   -2],\n",
       "        [  27,   93,  134,   -2],\n",
       "        [  15,  183,  288,   -2],\n",
       "        [  37,   95,  337,   -2],\n",
       "        [   8,   42,   -2,   -2],\n",
       "        [  23,  205, 1134,   -2],\n",
       "        [   0,  115, 1465,   -2],\n",
       "        [  15,  217,  804,   -2],\n",
       "        [   2,    2,   37,    7],\n",
       "        [   6,    6,  171,   -2],\n",
       "        [  15,   37,   -2,   -2],\n",
       "        [  27,  247,  431,   -2],\n",
       "        [   0,  308, 2438,   -2],\n",
       "        [   8,   60,  870,   -2],\n",
       "        [   8,  488,   -2,   -2],\n",
       "        [  52,  463, 2160,  198],\n",
       "        [  13,  140,  208,   -2],\n",
       "        [  15,  217, 1202,   -2],\n",
       "        [  49,  200,  482,   -2],\n",
       "        [   0,  444,   -2,   -2],\n",
       "        [  17,   82,  559,   -2],\n",
       "        [  15,  217, 1202,   -2],\n",
       "        [  10,  492,   -2,   -2],\n",
       "        [  16,  454, 2141,   -2],\n",
       "        [  20,   34, 1756,   -2],\n",
       "        [   1,   22,   24,   -2],\n",
       "        [  33,  324,  768,   -2],\n",
       "        [  27,   57, 1115,   -2],\n",
       "        [  16,  178,  751,   -2],\n",
       "        [  34,   67, 1655,   -2],\n",
       "        [   4,   69,   90,   -2],\n",
       "        [  18,   40,   -2,   -2],\n",
       "        [  13,  140,  208,   -2],\n",
       "        [  20,   34, 1756,   -2],\n",
       "        [  15,  183,   -2,   -2],\n",
       "        [   1,  198,   -2,   -2],\n",
       "        [   1,   22, 1771,   -2],\n",
       "        [   8,   42,   50,   -2],\n",
       "        [   8,  110,  125,   -2],\n",
       "        [   2,    2,   -2,   -2],\n",
       "        [  33,   61,  115,   -2],\n",
       "        [  27,   64,   93,   -2],\n",
       "        [  39,  234,  388,   -2],\n",
       "        [   0,   96,  540,   -2],\n",
       "        [   6,   87,  550,   -2],\n",
       "        [  24,   35,  153,   -2],\n",
       "        [  40,  248,  567,   -2],\n",
       "        [  39,  182,  683,   -2],\n",
       "        [  20,   34,   -2,   -2],\n",
       "        [  19,   52,  128,   -2],\n",
       "        [  13,  231,  716,   -2],\n",
       "        [  11,  478,   -2,   -2],\n",
       "        [  33,  261,  766,   -2],\n",
       "        [  15,  217,  347,   -2],\n",
       "        [   8,   76,  105,   -2],\n",
       "        [  10,    9,  344,   43],\n",
       "        [  10,  222, 2084,   -2],\n",
       "        [   6,   42,  202,   -2],\n",
       "        [  33,  290,   -2,   -2],\n",
       "        [   6,    6,    9,   -2],\n",
       "        [  23,  205, 1312,   -2],\n",
       "        [  15,  243, 1080,   -2],\n",
       "        [  24,  439, 1612,   -2],\n",
       "        [  34,  385, 2226,   -2],\n",
       "        [  24,   31,   34,   -2],\n",
       "        [  34,  385, 2266,   -2],\n",
       "        [  26,  210,  397,   -2],\n",
       "        [   0,  498, 2429,   -2],\n",
       "        [   8,   88, 1000,   -2],\n",
       "        [  23,  205, 1792,   -2],\n",
       "        [   8,   42,  213,   -2],\n",
       "        [  12,  256, 1353,   -2],\n",
       "        [  23,   72,   97,   -2],\n",
       "        [  10,  219,  635,   -2],\n",
       "        [   0,    0,    1,   -2],\n",
       "        [  50,  218,  349,   71],\n",
       "        [   2,    2,   51,   -2],\n",
       "        [   5,    5,   -2,   -2],\n",
       "        [  26,  283, 1236,   -2],\n",
       "        [   5,   29,   31,   -2],\n",
       "        [  43,  436, 2152,   -2],\n",
       "        [  21,   26,   28,   -2],\n",
       "        [   2,    2,   37,   -2],\n",
       "        [   8,   42,  202,   -2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(v_l[1]))['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/media/data/kakao/multi/test.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B221.146.21.119/media/data/kakao/multi/test.ipynb#ch0000014vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(v_l))[\u001b[39m'\u001b[39;49m\u001b[39mlabels\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "next(iter(v_l))['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_loaders_test(fn, tokenizer, config):\n",
    "    '''\n",
    "        fn : train_df path\n",
    "        tokenizer : bertTokenizer\n",
    "        img : img path\n",
    "        \n",
    "    '''\n",
    "    # Get list of labels and list of texts.\n",
    "    train_df=pd.read_csv(fn)\n",
    "    print(train_df.head())\n",
    "    train_df['img_idx'] = train_df.index\n",
    "\n",
    "    texts=train_df['product']\n",
    "    bcateid = train_df['bcateid']\n",
    "    mcateid = train_df['mcateid']\n",
    "    scateid = train_df['scateid']\n",
    "    dcateid = train_df['dcateid']\n",
    "    labels = list(zip(bcateid, mcateid, scateid, dcateid))\n",
    "    imgs = train_df['img_idx']\n",
    "\n",
    "    # Get dataloaders using given tokenizer as collate_fn.\n",
    "    train_loader = DataLoader(\n",
    "        ClassificationDataset(texts, labels, imgs, config.img_path),\n",
    "        batch_size= config.batch_size,      ########################################\n",
    "        collate_fn=ClassificationCollator(tokenizer, config.max_length), ########################\n",
    "    )\n",
    "\n",
    "    return train_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/media/deep/kakao/multi\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 18])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distutils import text_file\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    '''\n",
    "        text, img, label\n",
    "        if img None -> return img:None\n",
    "    '''\n",
    "    def __init__(self, texts, labels, img, img_path, tokenizer, max_len=30):\n",
    "        '''\n",
    "            texts : [bs, seq, hs]\n",
    "            labels : [bs, 1]\n",
    "        '''\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.imgs = img\n",
    "        self.img_h5_path = img_path\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_len\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        with h5py.File(self.img_h5_path, 'r') as img_feats:\n",
    "            img_feat = img_feats['img_feat'][self.imgs[item]]\n",
    "\n",
    "        img_feat = torch.FloatTensor(img_feat).reshape(1,-1)\n",
    "\n",
    "        encoding = self.tokenizer(   # __call__\n",
    "            text,\n",
    "            padding=True,\n",
    "            truncation=True,      # maximum length로 잘라.\n",
    "            return_tensors=\"pt\",  # pytorch 타입으로 리턴\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        ### [bs, seq, 1]   # 왜 1이냐면, next iter해서 하나의 idx만 가지고 온거야.\n",
    "\n",
    "        return_value = {\n",
    "            'input_ids': encoding['input_ids'],\n",
    "            'attention_mask': encoding['attention_mask'],\n",
    "            'labels': torch.tensor(label, dtype=torch.long),\n",
    "            'imgs': img_feat\n",
    "        }\n",
    "        \n",
    "        return return_value\n",
    "\n",
    "# v_load = DataLoader(ClassificationDataset(texts[idx:], labels[idx:], imgs[idx:], config.img_path, tokenizer),\n",
    "#                     batch_size = 128)\n",
    "# bb = next(iter(v_load))\n",
    "\n",
    "# bb['input_ids'].shape\n",
    "\n",
    "tokenizer(texts[0],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        max_length=30)['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 17796, 28671, 15419,     3]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([  3, 274, 514,  -2]),\n",
       " 'imgs': tensor([[0.5816, 0.0561, 0.6432,  ..., 0.4215, 0.0869, 0.0255]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6cb6a2577028e29b51ef669c1bb0b3f3b557177543697511c9ad985cb756fa2f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('anomaly')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
